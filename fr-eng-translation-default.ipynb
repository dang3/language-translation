{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\dangd\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:493: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "c:\\users\\dangd\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:494: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "c:\\users\\dangd\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:495: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "c:\\users\\dangd\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:496: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "c:\\users\\dangd\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:497: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "c:\\users\\dangd\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:502: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tf.keras.models import Model  # This does not work!\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.layers import Input, Dense, GRU, Embedding\n",
    "from tensorflow.python.keras.optimizers import RMSprop\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 10000\n",
    "num_epochs = 10\n",
    "state_size = 512\n",
    "embedding_size = 128  # 128\n",
    "num_layers = 3\n",
    "shutdown = False\n",
    "path_checkpoint = 'default_checkpoint.keras'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.5.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.2-tf'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download data set from Europarl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import europarl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using French to English dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "language_code='fr'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokens for start and end of translation sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mark_start = 'ssss '\n",
    "mark_end = ' eeee'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has apparently already been downloaded and unpacked.\n"
     ]
    }
   ],
   "source": [
    "europarl.maybe_download_and_extract(language_code=language_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for source language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'europarl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-dd24e340d490>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m data_src = europarl.load_data(english=False,\n\u001b[0m\u001b[0;32m      2\u001b[0m                               language_code=language_code)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'europarl' is not defined"
     ]
    }
   ],
   "source": [
    "data_src = europarl.load_data(english=False,\n",
    "                              language_code=language_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load data for target language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dest = europarl.load_data(english=True,\n",
    "                               language_code=language_code,\n",
    "                               start=mark_start,\n",
    "                               end=mark_end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenize the data, convert text to numbers, assign int to every unique word, then convert tokens into vectors of floating-point numbers using embeddig layer. Use num_words most frequent words in the data-set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TokenizerWrap(Tokenizer):\n",
    "    \"\"\"Wrap the Tokenizer-class from Keras with more functionality.\"\"\"\n",
    "    \n",
    "    def __init__(self, texts, padding,\n",
    "                 reverse=False, num_words=None):\n",
    "        \"\"\"\n",
    "        :param texts: List of strings. This is the data-set.\n",
    "        :param padding: Either 'post' or 'pre' padding.\n",
    "        :param reverse: Boolean whether to reverse token-lists.\n",
    "        :param num_words: Max number of words to use.\n",
    "        \"\"\"\n",
    "\n",
    "        Tokenizer.__init__(self, num_words=num_words)\n",
    "\n",
    "        # Create the vocabulary from the texts.\n",
    "        self.fit_on_texts(texts)\n",
    "\n",
    "        # Create inverse lookup from integer-tokens to words.\n",
    "        self.index_to_word = dict(zip(self.word_index.values(),\n",
    "                                      self.word_index.keys()))\n",
    "\n",
    "        # Convert all texts to lists of integer-tokens.\n",
    "        # Note that the sequences may have different lengths.\n",
    "        self.tokens = self.texts_to_sequences(texts)\n",
    "\n",
    "        if reverse:\n",
    "            # Reverse the token-sequences.\n",
    "            self.tokens = [list(reversed(x)) for x in self.tokens]\n",
    "        \n",
    "            # Sequences that are too long should now be truncated\n",
    "            # at the beginning, which corresponds to the end of\n",
    "            # the original sequences.\n",
    "            truncating = 'pre'\n",
    "        else:\n",
    "            # Sequences that are too long should be truncated\n",
    "            # at the end.\n",
    "            truncating = 'post'\n",
    "\n",
    "        # The number of integer-tokens in each sequence.\n",
    "        self.num_tokens = [len(x) for x in self.tokens]\n",
    "\n",
    "        # Max number of tokens to use in all sequences.\n",
    "        # We will pad / truncate all sequences to this length.\n",
    "        # This is a compromise so we save a lot of memory and\n",
    "        # only have to truncate maybe 5% of all the sequences.\n",
    "        self.max_tokens = np.mean(self.num_tokens) \\\n",
    "                          + 2 * np.std(self.num_tokens)\n",
    "        self.max_tokens = int(self.max_tokens)\n",
    "\n",
    "        # Pad / truncate all token-sequences to the given length.\n",
    "        # This creates a 2-dim numpy matrix that is easier to use.\n",
    "        self.tokens_padded = pad_sequences(self.tokens,\n",
    "                                           maxlen=self.max_tokens,\n",
    "                                           padding=padding,\n",
    "                                           truncating=truncating)\n",
    "\n",
    "    def token_to_word(self, token):\n",
    "        \"\"\"Lookup a single word from an integer-token.\"\"\"\n",
    "\n",
    "        word = \" \" if token == 0 else self.index_to_word[token]\n",
    "        return word \n",
    "\n",
    "    def tokens_to_string(self, tokens):\n",
    "        \"\"\"Convert a list of integer-tokens to a string.\"\"\"\n",
    "\n",
    "        # Create a list of the individual words.\n",
    "        words = [self.index_to_word[token]\n",
    "                 for token in tokens\n",
    "                 if token != 0]\n",
    "        \n",
    "        # Concatenate the words to a single string\n",
    "        # with space between all the words.\n",
    "        text = \" \".join(words)\n",
    "\n",
    "        return text\n",
    "    \n",
    "    def text_to_tokens(self, text, reverse=False, padding=False):\n",
    "        \"\"\"\n",
    "        Convert a single text-string to tokens with optional\n",
    "        reversal and padding.\n",
    "        \"\"\"\n",
    "\n",
    "        # Convert to tokens. Note that we assume there is only\n",
    "        # a single text-string so we wrap it in a list.\n",
    "        tokens = self.texts_to_sequences([text])\n",
    "        tokens = np.array(tokens)\n",
    "\n",
    "        if reverse:\n",
    "            # Reverse the tokens.\n",
    "            tokens = np.flip(tokens, axis=1)\n",
    "\n",
    "            # Sequences that are too long should now be truncated\n",
    "            # at the beginning, which corresponds to the end of\n",
    "            # the original sequences.\n",
    "            truncating = 'pre'\n",
    "        else:\n",
    "            # Sequences that are too long should be truncated\n",
    "            # at the end.\n",
    "            truncating = 'post'\n",
    "\n",
    "        if padding:\n",
    "            # Pad and truncate sequences to the given length.\n",
    "            tokens = pad_sequences(tokens,\n",
    "                                   maxlen=self.max_tokens,\n",
    "                                   padding='pre',\n",
    "                                   truncating=truncating)\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create tokenizer for source and target languages. Input sequences are reversed and padded with zeroes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer_src = TokenizerWrap(texts=data_src,\n",
    "                              padding='pre', # padding='pre'\n",
    "                              reverse=True,  # reverse=True\n",
    "                              num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tokenizer_dest = TokenizerWrap(texts=data_dest,\n",
    "                               padding='post',\n",
    "                               reverse=False,\n",
    "                               num_words=num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2007723, 55)\n",
      "(2007723, 56)\n"
     ]
    }
   ],
   "source": [
    "tokens_src = tokenizer_src.tokens_padded\n",
    "tokens_dest = tokenizer_dest.tokens_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_start = tokenizer_dest.word_index[mark_start.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_end = tokenizer_dest.word_index[mark_end.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = tokens_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2007723, 55)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data = tokens_dest[:, :-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2007723, 55)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_data = tokens_dest[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None, ), name='encoder_input')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the embedding-layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_embedding = Embedding(input_dim=num_words,\n",
    "                              output_dim=embedding_size,\n",
    "                              name='encoder_embedding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates the 3 GRU layers that will map from a sequence of embedding-vectors to a single \"thought vector\" which summarizes the contents of the input-text. Note that the last GRU-layer does not return a sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "encoder_gru1 = GRU(state_size, name='encoder_gru1',\n",
    "                   return_sequences=True)\n",
    "encoder_gru2 = GRU(state_size, name='encoder_gru2',\n",
    "                   return_sequences=True)\n",
    "encoder_gru3 = GRU(state_size, name='encoder_gru3',\n",
    "                   return_sequences=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_encoder():\n",
    "    # Start the neural network with its input-layer.\n",
    "    net = encoder_input\n",
    "    \n",
    "    # Connect the embedding-layer.\n",
    "    net = encoder_embedding(net)\n",
    "\n",
    "    # Connect all the GRU-layers.\n",
    "\n",
    "    net = encoder_gru1(net)\n",
    "    net = encoder_gru2(net)\n",
    "    net = encoder_gru3(net)\n",
    "\n",
    "\n",
    "    # This is the output of the encoder.\n",
    "    encoder_output = net\n",
    "    \n",
    "    return encoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\dangd\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py:1456: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "encoder_output = connect_encoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_initial_state = Input(shape=(state_size,),\n",
    "                              name='decoder_initial_state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decoder also needs a sequence of integer-tokens as inputs. During training we will supply this with a full sequence of integer-tokens e.g. corresponding to the text \"ssss once upon a time eeee\". \n",
    "\n",
    "During inference when we are translating new input-texts, we will start by feeding a sequence with just one integer-token for \"ssss\" which marks the beginning of a text, and combined with the \"thought vector\" from the encoder, the decoder will hopefully be able to produce the correct next word e.g. \"once\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = Input(shape=(None, ), name='decoder_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_embedding = Embedding(input_dim=num_words,\n",
    "                              output_dim=embedding_size,\n",
    "                              name='decoder_embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# decoder_list = []\n",
    "\n",
    "# for i in range(num_layers):\n",
    "#     decoder_list.append(GRU(state_size, name='decoder_gru' + str(i),return_sequences=True))\n",
    "\n",
    "\n",
    "decoder_gru1 = GRU(state_size, name='decoder_gru1',\n",
    "                   return_sequences=True)\n",
    "decoder_gru2 = GRU(state_size, name='decoder_gru2',\n",
    "                   return_sequences=True)\n",
    "decoder_gru3 = GRU(state_size, name='decoder_gru3',\n",
    "                   return_sequences=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_dense = Dense(num_words,\n",
    "                      activation='linear',\n",
    "                      name='decoder_output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect_decoder(initial_state):\n",
    "    # Start the decoder-network with its input-layer.\n",
    "    net = decoder_input\n",
    "\n",
    "    # Connect the embedding-layer.\n",
    "    net = decoder_embedding(net)\n",
    "    \n",
    "    # Connect all the GRU-layers.\n",
    "#     for dencoder in dencoder_layers:\n",
    "#         net = dencoder(net, initial_state=initial_state)\n",
    "    \n",
    "    \n",
    "    net = decoder_gru1(net, initial_state=initial_state)\n",
    "    net = decoder_gru2(net, initial_state=initial_state)\n",
    "    net = decoder_gru3(net, initial_state=initial_state)\n",
    "\n",
    "    # Connect the final dense layer that converts to\n",
    "    # one-hot encoded arrays.\n",
    "    decoder_output = decoder_dense(net)\n",
    "    \n",
    "    return decoder_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect and Create the Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = connect_decoder(initial_state=encoder_output)\n",
    "\n",
    "model_train = Model(inputs=[encoder_input, decoder_input],\n",
    "                    outputs=[decoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_encoder = Model(inputs=[encoder_input],\n",
    "                      outputs=[encoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = connect_decoder(initial_state=decoder_initial_state)\n",
    "\n",
    "model_decoder = Model(inputs=[decoder_input, decoder_initial_state],\n",
    "                      outputs=[decoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_train.compile(optimizer=optimizer,\n",
    "#                     loss='sparse_categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sparse_cross_entropy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate the cross-entropy loss between y_true and y_pred.\n",
    "    \n",
    "    y_true is a 2-rank tensor with the desired output.\n",
    "    The shape is [batch_size, sequence_length] and it\n",
    "    contains sequences of integer-tokens.\n",
    "\n",
    "    y_pred is the decoder's output which is a 3-rank tensor\n",
    "    with shape [batch_size, sequence_length, num_words]\n",
    "    so that for each sequence in the batch there is a one-hot\n",
    "    encoded array of length num_words.\n",
    "    \"\"\"\n",
    "\n",
    "    # Calculate the loss. This outputs a\n",
    "    # 2-rank tensor of shape [batch_size, sequence_length]\n",
    "    loss = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true,\n",
    "                                                          logits=y_pred)\n",
    "\n",
    "    # Keras may reduce this across the first axis (the batch)\n",
    "    # but the semantics are unclear, so to be sure we use\n",
    "    # the loss across the entire 2-rank tensor, we reduce it\n",
    "    # to a single scalar with the mean function.\n",
    "    loss_mean = tf.reduce_mean(loss)\n",
    "\n",
    "    return loss_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the Training Model\n",
    "\n",
    "We have used the Adam optimizer in many of the previous tutorials, but it seems to diverge in some of these experiments with Recurrent Neural Networks. RMSprop seems to work much better for these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = RMSprop(lr=1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be another bug in Keras so it cannot automatically deduce the correct shape of the decoder's output data. We therefore need to manually create a placeholder variable for the decoder's output. The shape is set to `(None, None)` which means the batch can have an arbitrary number of sequences, which can have an arbitrary number of integer-tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_target = tf.placeholder(dtype='int32', shape=(None, None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compile the model using our custom loss-function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\dangd\\anaconda3\\envs\\test\\lib\\site-packages\\tensorflow\\python\\keras\\_impl\\keras\\backend.py:1557: calling reduce_mean (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "model_train.compile(optimizer=optimizer,\n",
    "                    loss=sparse_cross_entropy,\n",
    "                    target_tensors=[decoder_target])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callback Functions\n",
    "\n",
    "During training we want to save checkpoints and log the progress to TensorBoard so we create the appropriate callbacks for Keras.\n",
    "\n",
    "This is the callback for writing checkpoints during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the callback for stopping the optimization when performance worsens on the validation-set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=3, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the callback for writing the TensorBoard log during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "callback_tensorboard = TensorBoard(log_dir='./21_logs/',\n",
    "                                   histogram_freq=0,\n",
    "                                   write_graph=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint,\n",
    "             callback_tensorboard]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Checkpoint\n",
    "\n",
    "You can reload the last saved checkpoint so you don't have to train the model every time you want to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_train.load_weights(path_checkpoint)\n",
    "    print(\"loaded\")\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the Model\n",
    "\n",
    "We wrap the data in named dicts so we are sure the data is assigned correctly to the inputs and outputs of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = \\\n",
    "{\n",
    "    'encoder_input': encoder_input_data,\n",
    "    'decoder_input': decoder_input_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = \\\n",
    "{\n",
    "    'decoder_output': decoder_output_data\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want a validation-set of 10000 sequences but Keras needs this number as a fraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004980766769121039"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_split = 10000 / len(encoder_input_data)\n",
    "validation_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the model. One epoch of training took about 1 hour on a GTX 1070 GPU. You probably need to run 10 epochs or more during training. After 10 epochs the loss was about 1.10 on the training-set and about 1.15 on the validation-set.\n",
    "\n",
    "Note the batch-size of 512 which was chosen because it kept the GPU running at nearly 100% while being within the memory limits of 8GB for this GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1997723 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "1997312/1997723 [============================>.]1997312/1997723 [============================>.] - ETA: 0s - loss: 1.2132Epoch 00001: val_loss improved from inf to 1.26801, saving model to 4layers_checkpoint.keras\n",
      "1997723/1997723 [==============================]1997723/1997723 [==============================] - 4429s 2ms/step - loss: 1.2132 - val_loss: 1.2680\n",
      "\n",
      "Epoch 2/2\n",
      "1997312/1997723 [============================>.]1997312/1997723 [============================>.] - ETA: 0s - loss: 1.1943Epoch 00002: val_loss improved from 1.26801 to 1.25721, saving model to 4layers_checkpoint.keras\n",
      "1997723/1997723 [==============================]1997723/1997723 [==============================] - 4386s 2ms/step - loss: 1.1943 - val_loss: 1.2572\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras._impl.keras.callbacks.History at 0x2d474d3b240>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_train.fit(x=x_data,\n",
    "                y=y_data,\n",
    "                batch_size=512,\n",
    "                epochs=num_epochs,\n",
    "                validation_split=validation_split,\n",
    "                callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translate Texts\n",
    "\n",
    "This function translates a text from the source-language to the destination-language and optionally prints a true translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "def translate(input_text, true_output_text=None, output_path=None):\n",
    "    \"\"\"Translate a single text-string.\"\"\"\n",
    "\n",
    "    # Convert the input-text to integer-tokens.\n",
    "    # Note the sequence of tokens has to be reversed.\n",
    "    # Padding is probably not necessary.\n",
    "    input_tokens = tokenizer_src.text_to_tokens(text=input_text,\n",
    "                                                reverse=True,\n",
    "                                                padding=True)\n",
    "    \n",
    "    # Get the output of the encoder's GRU which will be\n",
    "    # used as the initial state in the decoder's GRU.\n",
    "    # This could also have been the encoder's final state\n",
    "    # but that is really only necessary if the encoder\n",
    "    # and decoder use the LSTM instead of GRU because\n",
    "    # the LSTM has two internal states.\n",
    "    initial_state = model_encoder.predict(input_tokens)\n",
    "\n",
    "    # Max number of tokens / words in the output sequence.\n",
    "    max_tokens = tokenizer_dest.max_tokens\n",
    "\n",
    "    # Pre-allocate the 2-dim array used as input to the decoder.\n",
    "    # This holds just a single sequence of integer-tokens,\n",
    "    # but the decoder-model expects a batch of sequences.\n",
    "    shape = (1, max_tokens)\n",
    "    decoder_input_data = np.zeros(shape=shape, dtype=np.int)\n",
    "\n",
    "    # The first input-token is the special start-token for 'ssss '.\n",
    "    token_int = token_start\n",
    "\n",
    "    # Initialize an empty output-text.\n",
    "    output_text = ''\n",
    "\n",
    "    # Initialize the number of tokens we have processed.\n",
    "    count_tokens = 0\n",
    "\n",
    "    # While we haven't sampled the special end-token for ' eeee'\n",
    "    # and we haven't processed the max number of tokens.\n",
    "    while token_int != token_end and count_tokens < max_tokens:\n",
    "        # Update the input-sequence to the decoder\n",
    "        # with the last token that was sampled.\n",
    "        # In the first iteration this will set the\n",
    "        # first element to the start-token.\n",
    "        decoder_input_data[0, count_tokens] = token_int\n",
    "\n",
    "        # Wrap the input-data in a dict for clarity and safety,\n",
    "        # so we are sure we input the data in the right order.\n",
    "        x_data = \\\n",
    "        {\n",
    "            'decoder_initial_state': initial_state,\n",
    "            'decoder_input': decoder_input_data\n",
    "        }\n",
    "\n",
    "        # Note that we input the entire sequence of tokens\n",
    "        # to the decoder. This wastes a lot of computation\n",
    "        # because we are only interested in the last input\n",
    "        # and output. We could modify the code to return\n",
    "        # the GRU-states when calling predict() and then\n",
    "        # feeding these GRU-states as well the next time\n",
    "        # we call predict(), but it would make the code\n",
    "        # much more complicated.\n",
    "\n",
    "        # Input this data to the decoder and get the predicted output.\n",
    "        decoder_output = model_decoder.predict(x_data)\n",
    "\n",
    "        # Get the last predicted token as a one-hot encoded array.\n",
    "        token_onehot = decoder_output[0, count_tokens, :]\n",
    "        \n",
    "        # Convert to an integer-token.\n",
    "        token_int = np.argmax(token_onehot)\n",
    "\n",
    "        # Lookup the word corresponding to this integer-token.\n",
    "        sampled_word = tokenizer_dest.token_to_word(token_int)\n",
    "\n",
    "        # Append the word to the output-text.\n",
    "        output_text += \" \" + sampled_word\n",
    "\n",
    "        # Increment the token-counter.\n",
    "        count_tokens += 1\n",
    "\n",
    "    # Sequence of tokens output by the decoder.\n",
    "    output_tokens = decoder_input_data[0]\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as file:\n",
    "        # Print the input-text.\n",
    "        print(\"Input text:\")\n",
    "        print(input_text)\n",
    "        print()\n",
    "        \n",
    "        file.write(\"Input text:\\n\")\n",
    "        file.write(input_text + \"\\n\")\n",
    "\n",
    "        # Print the translated output-text.\n",
    "        print(\"Translated text:\")\n",
    "        print(output_text)\n",
    "        print()\n",
    "        \n",
    "        file.write(\"Translated text:\\n\")\n",
    "        file.write(output_text + \"\\n\")\n",
    "\n",
    "        # Optionally print the true translated text.\n",
    "        if true_output_text is not None:\n",
    "            print(\"True output text:\")\n",
    "            print(true_output_text)\n",
    "            print()\n",
    "            \n",
    "            file.write(\"True output text:\\n\")\n",
    "            file.write(true_output_text + \"\\n\")\n",
    "            \n",
    "        \n",
    "        # print bleu score\n",
    "        ref = true_output_text.lower().split()\n",
    "        pred = output_text.lower().split()\n",
    "        del pred[len(pred)-1]\n",
    "        \n",
    "        smoothing = nltk.translate.bleu_score.SmoothingFunction().method5\n",
    "        bleuScore = nltk.translate.bleu_score.sentence_bleu([ref], pred,smoothing_function=smoothing)\n",
    "        print(\"BLEU Score: \" + str(bleuScore))\n",
    "        file.write(\"BLEU Score: \" + str(bleuScore))\n",
    "        file.write(\"\\n*******************\\n\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples\n",
    "\n",
    "Translate a text from the training-data. This translation is quite good. Note how it is not identical to the translation from the training-data, but the actual meaning is similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcTrain_short_fr = [\t# less than 10 words\n",
    "'Les modifications n\\'ont pas lieu d\\'être',\n",
    "'Il me semble que c\\'est une bonne formule',\n",
    "'Êtes-vous satisfait du rythme de ces progrès',\n",
    "'C\\'est grotesque et cela doit cesser',\n",
    "'Le débat est clos',\n",
    "'Il devrait être considéré séparément',\n",
    "'J\\'ai voté \\\"pour\\\"',\n",
    "'Je voudrais évoquer quelques points spécifiques',\n",
    "'Elles n\\'avaient pas dégagé de majorité à l\\'époque',\n",
    "'Sans approvisionnement, leur santé et leurs vies sont en danger'\n",
    "]\n",
    "\n",
    "srcTrain_short_en = [\t# less than 10 words\n",
    "'There is no room for amendments',\n",
    "'This seems to me to be a workable solution',\n",
    "'Are you satisfied with this rate of progress',\n",
    "'This is an obscenity and it must be stopped',\n",
    "'The debate is closed',\n",
    "'It should be taken separately',\n",
    "'My vote is in favour',\n",
    "'I should like to mention a few specific points',\n",
    "'There was no majority for this at the time',\n",
    "'Without supplies, their health and their lives can be at risk',\n",
    "]\n",
    "\n",
    "srcTrain_medium_fr = [ # 11-25 words\n",
    "'Si votre décision est que je ne puis pas donner d\\'explication de vote, je l\\'accepte, mais avec certaines réserves',\n",
    "'Il faut que les propositions qui en sortiront offrent un signal clair que l\\'Europe doit être fondée sur ses nations et qu\\'elle respectera leurs droits',\n",
    "'Dans un domaine un peu différent, l\\'Europe dispose d\\'une législation stipulant ce que sont les produits régionaux',\n",
    "'Dans le premier rapport du Parlement, nous avons déjà souligné quelques points',\n",
    "'Monsieur le Président, je dois tout d\\'abord vous rappeler que nous ne connaissons encore ni les causes exactes, ni le déroulement des événements',\n",
    "'Mais il s\\'agit effectivement d\\'un problème auquel nombre de citoyens européens sont confrontés chaque jour',\n",
    "'Nous disposons d\\'assez d\\'options dans le système actuel pour assurer l\\'ouverture des marchés et la libre concurrence',\n",
    "'Monsieur le Président, la concurrence est l\\'âme et le moteur de la politique européenne en matière de marché intérieur',\n",
    "'La question qui se pose maintenant est de savoir si l\\'Union européenne participe aussi à cette lutte',\n",
    "'Dans ce contexte, je soutiens les appels à renforcer les contrôles effectués par l\\'État du port afin de garantir une inspection complète et efficace',\n",
    "]\n",
    "\n",
    "srcTrain_medium_en = [ # 11-25 words\n",
    "'If your ruling is that I cannot give an explanation of vote, I accept that but with reservations',\n",
    "'The proposals that result from it must give out a clear signal that Europe must be built on its nations and that it will respect their laws',\n",
    "'In a slightly different area, there is legislation in Europe which defines precisely what regional products are',\n",
    "'We have already underlined a number of these principles in Parliament\\'s first report',\n",
    "'Mr President, firstly I have to remind you that we do not yet know the exact causes and the series of events',\n",
    "'But it is a problem which is affecting many European citizens on a daily basis',\n",
    "'There are enough other options in the present system to safeguard open markets and free competition',\n",
    "'Mr President, competition is at the heart of the European internal market policy and is also its driving force',\n",
    "'But the question is now: is the European Union doing anything about it as well',\n",
    "'In that context I support calls to strengthen port state control to ensure full and effective inspection',\n",
    "]\n",
    "\n",
    "srcTrain_long_fr = [\t# 26 > words\n",
    "'Sans prétendre à l\\'exhaustivité, celle-ci garantirait au moins trois points: aucun cargo ou pétrolier ne pourra plus mouiller dans un port de l\\'Union européenne s\\'il est bon pour la casse; toutes les personnes concernées, y compris l\\'affréteur du transport, sont responsables des dégâts qui peuvent survenir; et ces personnes doivent contracter des assurances suffisantes',\n",
    "'Je voudrais, Madame la Commissaire, vous égrener rapidement puisqu\\'ici le temps est très compté, les sept points qui nous paraissent, et vous en avez d\\'ailleurs cités quelques-uns, essentiels à travailler: la double coque le plus tôt possible dans nos eaux; le contrôle par l\\'État du port le plus sévère possible',\n",
    "'Outre les dommages irréparables causés à l\\'environnement, les dommages subis par l\\'écosystème et les pertes pour le secteur touristique, la marée noire est un véritable coup de massue pour la pêche, pour la conservation des ressources dans le milieu marin, et il faudra attendre de nombreuses années avant que ces côtes ne se remettent de cette catastrophe',\n",
    "'D\\'une part, il convient de demander à la Commission de prendre, dans le cadre des aides prévues pour le secteur de la pêche, des mesures spéciales visant à pallier les effets de cette catastrophe sur le secteur productif des zones concernées et d\\'exiger des organismes internationaux et d\\'elle-même un contrôle extrême des bateaux battant pavillon de complaisance',\n",
    "'Les dommages sociaux et économiques, dont on a déjà parlé ici aujourd\\'hui, en termes tant de perte d\\'emplois que de ressources marines et touristiques, sont d\\'une ampleur telle qu\\'ils justifient amplement une action décidée et marquante de la part des institutions communautaires',\n",
    "'Nous devons tenir compte de ce fait. Je ne suis pas d\\'accord avec ceux qui affirment sans nuance que l\\'effet de serre est responsable de cette tempête mais il est relativement certain que si nous ne changeons pas rapidement de cap, nous devons craindre d\\'autres catastrophes',\n",
    "'Monsieur le Commissaire, l\\'ignorance de certains États membres a plongé l\\'Europe dans une crise alimentaire de grande ampleur et je suis une fois de plus irrité, malheureusement, de constater l\\'absence totale et renouvelée du Conseil alors que vous présentez ce rapport intéressant',\n",
    "'Je suppose que la question a trait à la question de savoir où la compétence de cette autorité commence et prend fin et où la compétence et l\\'autorité des agences de sécurité alimentaire au sein des États membres commence et prend fin',\n",
    "'Je demanderai conseil aux services juridiques, en gardant à l\\'esprit, en particulier, que cela peut fournir une réponse rapide dans le cas où une législation communautaire, en attente d\\'un arrêt du tribunal, n\\'est pas respectée',\n",
    "'Il se peut que cela fasse l\\'objet de discussions ici et ailleurs. J\\'écouterai toute suggestion mais ma première conclusion est que cette autorité devrait occuper une position centrale plutôt que périphérique'\n",
    "]\n",
    "\n",
    "srcTrain_long_en = [\t# 26 > words\n",
    "'No tanker or freighter fit only for the scrap heap must ever put into any harbour within the European Union again. All those involved, including the transport agent, are responsible for any ensuing damage, and these individuals are to provide satisfactory assurances',\n",
    "'Commissioner, as time is very short, I would like to pick out the seven points which we feel, and you have already mentioned some of them, are essential to work on: double-hulled vessels in our waters as soon as possible and the strictest possible state control of ports. In particular, we must ensure that classification societies are compelled to make their reports public, as currently, we do not have access to them',\n",
    "'Because, as well as the irreparable damage to the environment, the damage to the ecosystem and losses in the tourist industry, the oil slick dealt a huge blow to the fishing industry, to the conservation of marine resources, and the damaged coast lines will take years to recover',\n",
    "'On the one hand, by asking the Commission, within the scope of aid to the fishing industry, to implement special measures to compensate for the effects of this catastrophe on the industry in the areas affected, and also by asking them to demand, of international bodies and of themselves, tight controls on ships which sail under flags of convenience',\n",
    "'The economic and social damage, which we have spoken about today, in terms of the loss of jobs and fishing and tourist resources, is so great that they fully justify decisive and thorough action on the part of the Community institutions',\n",
    "'We must be aware of this connection; I do not support those who make sweeping statements to the effect that the greenhouse effect is to blame for this storm, but one thing we can be relatively certain of is that we have reason to fear further catastrophes if we do not soon alter our course',\n",
    "'Commissioner, the ignorance of certain Member States has landed us in a major food crisis here in Europe, and I am afraid that once more I have cause to be angry at the fact that again no Members of the Council are in attendance, and that on the day that you present your interesting report',\n",
    "'I suspect that the question is focused on the issue of where the competence of the authority begins and ends and where the competence and authority of food safety agencies in Member States begin and end',\n",
    "'It will require the advice of legal services and that will be sought, particularly bearing in mind that it may provide a speedy response to a failure to comply with Community law pending a court ruling',\n",
    "'It may be a matter for discussion here and elsewhere and I will listen to any suggestions that are made but my preliminary conclusion is that this Authority should be located centrally rather than on the periphery',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Il devrait aider les entreprises à prendre notre ressource et en faire autre chose pour les gens de chez nous\n",
      "\n",
      "Translated text:\n",
      " it should help our businesses to invest and make our own people more attractive eeee\n",
      "\n",
      "True output text:\n",
      "It should help businesses to take our resource and develop other products from it for the good of our own people\n",
      "\n",
      "BLEU Score: 0.18862964447124536\n",
      "***********************\n",
      "Input text:\n",
      "Nous devons diversifier notre économie de manière à ne plus compter que sur une seule source de revenus tirée d'une même ressource naturelle\n",
      "\n",
      "Translated text:\n",
      " we must diversify our economy on the basis of a spirit of income which is based on a resource based on a resource of a resource source eeee\n",
      "\n",
      "True output text:\n",
      "We have to diversify our economy so that we do not rely on one source of revenue coming from one natural resource\n",
      "\n",
      "BLEU Score: 0.11919186667978673\n",
      "***********************\n",
      "Input text:\n",
      "Comme vous le savez, lorsque les ressources deviennent limitées, des conflits éclatent s'il y a apparence de répartition inégale\n",
      "\n",
      "Translated text:\n",
      " as you know when resources are limited there are conflicts of conflict eeee\n",
      "\n",
      "True output text:\n",
      "As we know, when resources become tight, when there seems to be an unfair distribution, then conflict often developsThe duty to accommodate is of vital importance to persons with disabilities as well as to groups such as religious minorities\n",
      "\n",
      "BLEU Score: 0.022981667481117844\n",
      "***********************\n",
      "Input text:\n",
      "Le devoir de satisfaire à leurs besoins est d'une importance fondamentale pour les personnes handicapées, de même que pour des groupes comme les minorités religieuses\n",
      "\n",
      "Translated text:\n",
      " it is important to have a fundamental understanding for people with disabilities and for religious groups as well as religious minorities eeee\n",
      "\n",
      "True output text:\n",
      "There is a lot in this bill that is right and that is worthy of our support as representatives of the people who elected us\n",
      "\n",
      "BLEU Score: 0.22332778228621797\n",
      "***********************\n",
      "Input text:\n",
      "Il y a beaucoup d'éléments positifs dans ce projet de loi, des éléments qui méritent que nous les appuyions au nom des gens qui nous ont élus\n",
      "\n",
      "Translated text:\n",
      " there are many positive elements in this draft legislation which we have to make the right to take on those who are elected by the people who elected us eeee\n",
      "\n",
      "True output text:\n",
      "It is very disappointing, especially since this bill is so important to so many of our fellow citizens\n",
      "\n",
      "BLEU Score: 0.22718030830695402\n",
      "***********************\n",
      "Input text:\n",
      "C'est très décevant, surtout qu'il s'agit d'un projet de loi d'une si grande importance pour un si grand nombre de nos concitoyens\n",
      "\n",
      "Translated text:\n",
      " that is very disappointing in particular by the fact that it is a very important project for many of us to be concerned about the importance of a large number of citizens eeee\n",
      "\n",
      "True output text:\n",
      "A further review of the human rights act and the human rights commission system is also needed\n",
      "\n",
      "BLEU Score: 0.2543029683891056\n",
      "***********************\n",
      "Input text:\n",
      "Un examen plus poussé de la Loi sur les droits de la personne et du système de la Commission des droits de la personne est également nécessaire\n",
      "\n",
      "Translated text:\n",
      " a more detailed examination of the law of the rights of the person and the committee on citizens' rights rights rights and rights is therefore the same eeee\n",
      "\n",
      "True output text:\n",
      "It does not, however, address the same complaint that many others may have across the country\n",
      "\n",
      "BLEU Score: 0.12806688057853163\n",
      "***********************\n",
      "Input text:\n",
      "Toutefois, elle n'examine pas la même plainte venant de nombreuses autres personnes ailleurs au pays\n",
      "\n",
      "Translated text:\n",
      " however it does not even have the same effect on many other countries eeee\n",
      "\n",
      "True output text:\n",
      "That is why I had the initial reservations with respect to the maximum sentence being only five years\n",
      "\n",
      "BLEU Score: 0.1300999890074045\n",
      "***********************\n",
      "Input text:\n",
      "C'est ce qui explique les réserves que j'ai eues au départ à propos de la peine maximale de cinq ans\n",
      "\n",
      "Translated text:\n",
      " that is the case with the reservations that i had initially expressed in the five years of five years eeee\n",
      "\n",
      "True output text:\n",
      "I believe this is something that is extremely important which did not exist previous to this legislation\n",
      "\n",
      "BLEU Score: 0.14989864323537883\n",
      "***********************\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now testing with sentences not from training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "srcTest_short_fr = [\n",
    "# From books\n",
    "# 'Souvent nos dimanches d\\'hiver se passaient ainsi',\n",
    "# 'Personne ne venait ouvrir à la visiteuse inconnue',\n",
    "# 'Je t\\'attendais pour te montrer',\n",
    "# 'Mais ma mère n\\'écoutait plus',\n",
    "# 'Personne ne répondit',\n",
    "# 'J\\'hésitai une seconde',\n",
    "# 'Alors ils crièrent',\n",
    "# 'Je répondis bien vite',\n",
    "# 'La conversation finit là',\n",
    "# 'Mais il est trop tard',\n",
    "# From canadian parliament\n",
    "'Elles ont été déposées',\n",
    "'Nous souffrons des compressions budgétaires aux aéroports',\n",
    "'C\\'était une bonne chose à mon avis',\n",
    "'Nous approuvons d\\'emblée certains aspects du projet de loi',\n",
    "'Nous invitons le gouvernement à faire preuve de modération',\n",
    "'Posez-vous cette question',\n",
    "'Qu\\'est-ce que les gens vont faire',\n",
    "'C\\'est inacceptable',\n",
    "'Ils n\\'auront pas le choix',\n",
    "'Les problèmes sont toujours là'\n",
    "]\n",
    "\n",
    "srcTest_short_en = [\n",
    " # From books\n",
    "# 'This is how our winter Sundays were often spent',\n",
    "# 'No one came to let in the unknown visitor',\n",
    "# 'I was waiting to show you',\n",
    "# 'But Mother was no longer listening',\n",
    "# 'No one answered',\n",
    "# 'I hesitated for a moment',\n",
    "# 'Then they shouted',\n",
    "# 'I replied at once',\n",
    "# 'The conversation ended there',\n",
    "# 'But it is too late', \n",
    "# From canadian parliament\n",
    "'They have been filed',\n",
    "'We suffer from the cuts to airports',\n",
    "'To me that was a good thing',\n",
    "'We are pleased with certain aspects of the bill',\n",
    "'We would encourage caution here',\n",
    "'Ask yourself that question',\n",
    "'What will people do',\n",
    "'This is unacceptable',\n",
    "'They will not have any choice',\n",
    "'The problems have not gone away'\n",
    "]\n",
    "\n",
    "\n",
    "srcTest_medium_fr = [\n",
    "# 'C\\'était un froid dimanche de novembre, le premier jour d\\'automne qui fît songer à l\\'hiver',\n",
    "# 'Mon père avait pris la lampe et, sans attendre, il ouvrait la porte qu\\'on avait déjà fermée à clef',\n",
    "# 'Puis, poussant la grille, s\\'avançant sur le bord des marches, il leva la lumière au-dessus de sa tête pour voir ce qui se passait',\n",
    "# 'les détails en sont trop longs à répéter, et je les ai entendus raconter de tant de façons que je puis à peine dire quel est le récit exact',\n",
    "# 'Vous n\\'irez jamais loin sans la coopération, la confiance et la camaraderie des autres hommes et femmes',\n",
    "# 'Je n\\'arrive pas à croire que vous ne soyez pas tout au moins disposé à envisager d\\'autres possibilités',\n",
    "# 'La culture joue un rôle actif dans la formation chez un individu du caractère, de l\\'attitude et du regard sur la vie',\n",
    "# 'Nous les humains avons une grande disposition à tordre les faits pour qu\\'ils s\\'ajustent à notre conclusion dès lors que nous en avons formé une',\n",
    "# 'Après avoir été diplômée de l\\'école, j\\'ai de nouveau emménagé chez moi et vécu avec mes parents durant trois ans',\n",
    "# 'Il y avait de nombreuses choses que nous voulions faire, mais nous ne sommes pas parvenus à faire beaucoup d\\'entre elles'\n",
    "# Canadian parliament\n",
    "'Il devrait aider les entreprises à prendre notre ressource et en faire autre chose pour les gens de chez nous',\n",
    "'Nous devons diversifier notre économie de manière à ne plus compter que sur une seule source de revenus tirée d\\'une même ressource naturelle',\n",
    "'Comme vous le savez, lorsque les ressources deviennent limitées, des conflits éclatent s\\'il y a apparence de répartition inégale',\n",
    "'Le devoir de satisfaire à leurs besoins est d\\'une importance fondamentale pour les personnes handicapées, de même que pour des groupes comme les minorités religieuses',\n",
    "'Il y a beaucoup d\\'éléments positifs dans ce projet de loi, des éléments qui méritent que nous les appuyions au nom des gens qui nous ont élus',\n",
    "'C\\'est très décevant, surtout qu\\'il s\\'agit d\\'un projet de loi d\\'une si grande importance pour un si grand nombre de nos concitoyens',\n",
    "'Un examen plus poussé de la Loi sur les droits de la personne et du système de la Commission des droits de la personne est également nécessaire',\n",
    "'Toutefois, elle n\\'examine pas la même plainte venant de nombreuses autres personnes ailleurs au pays',\n",
    "'C\\'est ce qui explique les réserves que j\\'ai eues au départ à propos de la peine maximale de cinq ans',\n",
    "'Je pense que c\\'est une mesure extrêmement importante qui n\\'existait pas auparavant' \n",
    "]\n",
    "\n",
    "srcTest_medium_en = [\n",
    "# 'It was a cold Sunday of November, the first day of autumn to make one think of winter',\n",
    "# 'Father had taken up the lamp and, without waiting, went to open the door which had already been locked',\n",
    "# 'Then pushing open the gate, he walked to the edge of the steps and raised his light above his head to see what was happening',\n",
    "# 'The circumstances are too long to repeat, and I have heard them related so many ways, that I can scarce be certain which is the right account',\n",
    "# 'You will never get far without the co-operation, confidence and comradeship of other men and women',\n",
    "# 'I can\\'t believe that you aren\\'t at least willing to consider the possibility of other alternatives',\n",
    "# 'Culture plays a dynamic role in shaping an individual\\'s character, attitude, and outlook on life',\n",
    "# 'We humans have a great way of twisting facts to fit our conclusion as soon as we have made one',\n",
    "# 'After I graduated from college, I moved back home and lived with my parents for three years',\n",
    "# 'There were many things that we wanted to do, but we never got around to doing many of them',\n",
    "# Canadian parliament\n",
    "'It should help businesses to take our resource and develop other products from it for the good of our own people',\n",
    "'We have to diversify our economy so that we do not rely on one source of revenue coming from one natural resource',\n",
    "'As we know, when resources become tight, when there seems to be an unfair distribution, then conflict often develops'\n",
    "'The duty to accommodate is of vital importance to persons with disabilities as well as to groups such as religious minorities',\n",
    "'There is a lot in this bill that is right and that is worthy of our support as representatives of the people who elected us',\n",
    "'It is very disappointing, especially since this bill is so important to so many of our fellow citizens',    \n",
    "'A further review of the human rights act and the human rights commission system is also needed',\n",
    "'It does not, however, address the same complaint that many others may have across the country', \n",
    "'That is why I had the initial reservations with respect to the maximum sentence being only five years',\n",
    "'I believe this is something that is extremely important which did not exist previous to this legislation'\n",
    "]\n",
    "\n",
    "srcTest_long_fr = [\n",
    "# 'Cette bonne femme avait aussi une petite école qu\\'elle tenait pour enseigner aux enfants à lire et à coudre; et ayant, comme j\\'ai dit, autrefois vécu en bonne façon, elle élevait les enfants avec beaucoup d\\'art autant qu\\'avec beaucoup de soin',\n",
    "# 'Mon avis est qu\\'on ne peut créer des personnages que lorsque l\\'on a beaucoup étudié les hommes, comme on ne peut parler une langue qu\\'a la condition de l\\'avoir sérieusement apprise',\n",
    "# 'C\\'était là une magnifique collection, et pas un de ces mille objets, si nécessaires à la toilette d\\'une femme comme celle chez qui nous étions, n\\'était en autre métal qu\\'or ou argent',\n",
    "# 'Le matin, elle avait manqué la messe; et jusqu\\'au sermon, assis dans le chœur avec les autres enfants, j\\'avais regardé anxieusement du côté des cloches, pour la voir entrer avec son chapeau neuf',\n",
    "# 'En effet, à la porte de la salle à manger – la plus rapprochée des cinq portes vitrées qui donnaient sur la cour – une femme aux cheveux gris, penchée, cherchait à voir au travers des rideaux',\n",
    "# 'Millie, sans doute, avait reçu le chapeau de La Gare, et sans rien entendre, au fond de la chambre rouge, devant un lit semé de vieux rubans et de plumes défrisées, elle cousait, décousait, rebâtissait sa médiocre coiffure',\n",
    "# 'Je ne reconnaissais plus la femme aux cheveux gris, que j\\'avais vue courbée devant la porte, une minute auparavant, avec cet air suppliant et hagard de poule qui aurait perdu l\\'oiseau sauvage de sa couvée',\n",
    "# 'Meaulnes ne disait rien; mais c\\'était pour lui qu\\'à chaque instant l\\'un des plus bavards s\\'avançait au milieu du groupe, et, prenant à témoin tour à tour chacun de ses compagnons, qui l\\'approuvaient bruyamment, racontait quelque longue histoire de maraude, que tous les autres suivaient, le bec ouvert, en riant silencieusement',\n",
    "# 'Si une nouvelle motion est présentée et si je la déclare recevable et vous demande d\\'accepter que le Sénat donne son consentement, aucune autre motion ne pourra être déposée par la suite et ce, tant que le Sénat n\\'aura pas donné son consentement',\n",
    "# 'Il y a encore une autre mesure dont nous devons nous occuper d\\'une manière ou d\\'une autre, sans quoi les policiers risquent de ne pas pouvoir perquisitionner dans les résidences pour recueillir des éléments de preuve'\n",
    "# canadian parliament\n",
    "'Si on s\\'attend à ce qu\\'il y ait une rationalisation, comment va-t-on faire pour inviter les provinces à accepter de rationaliser leurs travailleurs dans les usines, s\\'il n\\'y a pas d\\'arrimage avec ce qui va se passer au niveau de la capture',\n",
    "'Franchement, que cela nous plaise ou non, n\\'eut été des mesures prises par le gouvernement, ce serait bien étonnant si nous avions une entente internationale sur les stocks de poisson',\n",
    "'À cet égard, il faut rappeler qu\\'à cette époque, le débat avait porté sur le caractère licite ou illicite de ces nouvelles dispositions législatives en regard du droit international',\n",
    "'D\\'une façon générale, nous avons toujours été en faveur des changements au système de justice criminelle pour les personnes handicapées et je pense que les handicapés du Canada seront heureux de cette mesure et en profiteront largement',\n",
    "'Le député va dans la bonne direction, c\\'est-à-dire qu\\'il a le coeur accroché à la bonne place, mais je crois que nous pourrions mettre l\\'argent dans un régime de pension plus progressif',\n",
    "'Nous devrions tout au moins chercher à créer un régime fiscal qui traite avec neutralité les familles où les conjoints tendent à consacrer le plus de temps possible à leurs enfants, ou au moins, comme quelqu\\'un le suggérait, à modifier le régime afin d\\'établir une discrimination en faveur de ces familles',\n",
    "'Ces programmes ne visent pas à améliorer la situation économique des parents autant qu\\'à régler les aspects sociaux et les rapports entre les parents et l\\'enfant',\n",
    "'Les victimes n\\'ont plus qu\\'à consacrer les précieuses années qu\\'il leur reste à vivre à se battre devant les tribunaux pour obtenir l\\'indemnisation à laquelle elles ont droit',\n",
    "'Une conservation et une gestion appropriées de ces stocks pourraient contribuer grandement à assurer la durabilité de cette importante source d\\'alimentation pour les générations futures',\n",
    "'J\\'aimerais beaucoup que le gouvernement en profite pour saisir la Chambre de projets de loi importants que les Canadiens réclament et dont ils ont grand besoin'\n",
    "]\n",
    "\n",
    "srcTest_long_en = [\n",
    "# 'This woman had also had a little school, which she kept to teach children to read and to work; and having, as I have said, lived before that in good fashion, she bred up the children she took with a great deal of art, as well as with a great deal of care',\n",
    "# 'In my opinion, it is impossible to create characters until one has spent a long time in studying men, as it is impossible to speak a language until it has been seriously acquired',\n",
    "# 'It was a magnificent collection, and there was not one of those thousand little things so necessary to the toilet of a woman of the kind which was not in gold or silver',\n",
    "# 'That morning she missed Mass, and right up to the sermon, from my place in the choir with the other children, I looked anxiously towards the door to see her come to church wearing her new hat',\n",
    "# 'In fact, there stood, outside the dining-room door - the nearest of the five glass doors opening on the playground - a grey-headed woman, leaning forward and trying to look through the curtains',\n",
    "# 'Without any doubt Millie had received her hat from the station, and, hearing nothing, at the end of the red bedroom, before a bed bestrewed with old ribbons and uncurled feathers, she was stitching, undoing, and remaking her modest headgear',\n",
    "# 'I could no longer recognise the grey-headed woman whom, only a minute ago, I had seen stooping in front of the door, with the piteous and haggard bearing of a hen who has lost the wildest chick in her brood',\n",
    "# 'Meaulnes never said anything, but it was because of him that repeatedly one chatterbox or another, making of himself the centre of the group, and taking in turn each of his noisily approving friends as witness, would relate some long story of poaching, which the others followed with gaping mouths and inward laughter',\n",
    "# 'If a new motion comes forward and I find that it is in order and I ask that you agree to grant leave, then there can be no further motion put after that until such time as leave is granted',\n",
    "# 'We have a situation which could result in an inability on the part of the police forces in our country to search residences for evidence, unless we deal with it one way or the other',\n",
    "# canadian parliament\n",
    "'If rationalization is what they are hoping for, how are they going to persuade the provinces to go along with rationalizing their plant workers unless this is tied in with the catch'\n",
    "'Frankly, whether we like it or not, were it not for the actions of this government I would be surprised if we had an international agreement that deals with fish stocks'\n",
    "'It must be kept in mind that, at that time, the debate addressed whether or not these new legislative powers were legal according to international law'\n",
    "'We have always been generally supportive of changes to the criminal justice system for persons with disabilities and I believe that persons with disabilities in Canada will embrace the legislation and benefit greatly from it',\n",
    "'The member is going in the right direction in terms of his heart and is being very thoughtful, but again I think we could put the money into a more progressive pension system',\n",
    "'We ought to seek at the very least to create a tax code which treats families that seek to maximize their time with their children neutrally or at the very least, as someone proposed, we ought to make amendments to the tax code to positively discriminate in favour of such families',\n",
    "'These programs do not address the economic situation of the parents as much as they address the social aspect and the interplay between the parent and the child',\n",
    "'What is left now for these victims is that they will have to spend precious years of what is left of their lives in court fighting for compensation which they should rightfully receive',\n",
    "'Proper conservation and management of these stocks could make a significant contribution to ensuring the sustainability of this important food source for our future generations',\n",
    "'I really wish that this government would take an occasion like this to bring forward some substantial bills that the people out there are crying for, that they are demanding and that we need so desperately'\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Elles ont été déposées\n",
      "\n",
      "Translated text:\n",
      " they were tabled eeee\n",
      "\n",
      "True output text:\n",
      "They have been filed\n",
      "\n",
      "BLEU Score: 0.0766091750078838\n",
      "***********************\n",
      "Input text:\n",
      "Nous souffrons des compressions budgétaires aux aéroports\n",
      "\n",
      "Translated text:\n",
      " we are spending budgetary airports eeee\n",
      "\n",
      "True output text:\n",
      "We suffer from the cuts to airports\n",
      "\n",
      "BLEU Score: 0.07740189180437576\n",
      "***********************\n",
      "Input text:\n",
      "C'était une bonne chose à mon avis\n",
      "\n",
      "Translated text:\n",
      " i think that is a good thing eeee\n",
      "\n",
      "True output text:\n",
      "To me that was a good thing\n",
      "\n",
      "BLEU Score: 0.2771752356259992\n",
      "***********************\n",
      "Input text:\n",
      "Nous approuvons d'emblée certains aspects du projet de loi\n",
      "\n",
      "Translated text:\n",
      " we are certain that we are now in some aspects of the draft law eeee\n",
      "\n",
      "True output text:\n",
      "We are pleased with certain aspects of the bill\n",
      "\n",
      "BLEU Score: 0.1978116988049654\n",
      "***********************\n",
      "Input text:\n",
      "Nous invitons le gouvernement à faire preuve de modération\n",
      "\n",
      "Translated text:\n",
      " we call on the government to act in a manner eeee\n",
      "\n",
      "True output text:\n",
      "We would encourage caution here\n",
      "\n",
      "BLEU Score: 0.0769800358919501\n",
      "***********************\n",
      "Input text:\n",
      "Posez-vous cette question\n",
      "\n",
      "Translated text:\n",
      " you are going to raise this issue eeee\n",
      "\n",
      "True output text:\n",
      "Ask yourself that question\n",
      "\n",
      "BLEU Score: 0\n",
      "***********************\n",
      "Input text:\n",
      "Qu'est-ce que les gens vont faire\n",
      "\n",
      "Translated text:\n",
      " what is the people going to do eeee\n",
      "\n",
      "True output text:\n",
      "What will people do\n",
      "\n",
      "BLEU Score: 0.11913576983277992\n",
      "***********************\n",
      "Input text:\n",
      "C'est inacceptable\n",
      "\n",
      "Translated text:\n",
      " this is unacceptable eeee\n",
      "\n",
      "True output text:\n",
      "This is unacceptable\n",
      "\n",
      "BLEU Score: 0.703215867220802\n",
      "***********************\n",
      "Input text:\n",
      "Ils n'auront pas le choix\n",
      "\n",
      "Translated text:\n",
      " they will not have the choice eeee\n",
      "\n",
      "True output text:\n",
      "They will not have any choice\n",
      "\n",
      "BLEU Score: 0.5859402341761669\n",
      "***********************\n",
      "Input text:\n",
      "Les problèmes sont toujours là\n",
      "\n",
      "Translated text:\n",
      " the problems are always being solved eeee\n",
      "\n",
      "True output text:\n",
      "The problems have not gone away\n",
      "\n",
      "BLEU Score: 0.1475864223205105\n",
      "***********************\n"
     ]
    }
   ],
   "source": [
    "for fr, en in zip(srcTest_short_fr, srcTest_short_en):\n",
    "    translate(input_text=fr, true_output_text=en, output_path=\"results/default/srcTest_medium.txt\")\n",
    "    print(\"***********************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session.\n",
      "\n",
      "Translated text:\n",
      " you wanted a debate on this issue during the coming months eeee\n",
      "\n",
      "True output text:\n",
      "ssss You have requested a debate on this subject in the course of the next few days, during this part-session. eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "translate(input_text=data_src[idx],\n",
    "          true_output_text=data_dest[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example which is also a reasonable translation, although it has incorrectly translated the natural disasters. Note \"countries of the European Union\" has instead been translated as \"member states\" which are synonyms in this context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés.\n",
      "\n",
      "Translated text:\n",
      " in the meantime i would like to ask a number of members to be here i am asking for a silence in particular for example of all the victims of the various countries which have suffered in particular the european union eeee\n",
      "\n",
      "True output text:\n",
      "ssss In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union. eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 4\n",
    "translate(input_text=data_src[idx],\n",
    "          true_output_text=data_dest[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we join two texts from the training-set. The model first sends this combined text through the encoder, which produces a \"thought-vector\" that seems to summarize both texts reasonably well so the decoder can produce a reasonable translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session.En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés.\n",
      "\n",
      "Translated text:\n",
      " you had a debate on this issue during the next part session in the debate on a number of occasions i would like to ask you to ensure that i am sure that one of the victims of the european union will be particularly a number of people in the various countries of the european union\n",
      "\n",
      "True output text:\n",
      "ssss You have requested a debate on this subject in the course of the next few days, during this part-session. eeeessss In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union. eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "translate(input_text=data_src[idx] + data_src[idx+1],\n",
    "          true_output_text=data_dest[idx] + data_dest[idx+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we reverse the order of these two texts then the meaning is not quite so clear for the latter text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input text:\n",
      "En attendant, je souhaiterais, comme un certain nombre de collègues me l'ont demandé, que nous observions une minute de silence pour toutes les victimes, des tempêtes notamment, dans les différents pays de l'Union européenne qui ont été touchés.Vous avez souhaité un débat à ce sujet dans les prochains jours, au cours de cette période de session.\n",
      "\n",
      "Translated text:\n",
      " in the meantime i would like to ask you to be a number of speakers here i have been here in the european union who are victims of the various countries in the european union for example in a number of years to be held in this debate in the course of the next part session\n",
      "\n",
      "True output text:\n",
      "ssss In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union. eeeessss You have requested a debate on this subject in the course of the next few days, during this part-session. eeee\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idx = 3\n",
    "translate(input_text=data_src[idx+1] + data_src[idx],\n",
    "          true_output_text=data_dest[idx+1] + data_dest[idx])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
